# Uncertainty-Aware Music Genre Classification using Evidential Deep Learning

This repository contains the complete code and experimental setup to reproduce the results presented in our study on **uncertainty-aware music genre classification** using **Evidential Deep Learning (EDL)**. The proposed CNNâ€“LSTM-based evidential framework is evaluated on the **GTZAN dataset**, with a focus on **uncertainty quantification, calibration, and reliability-aware evaluation**.

---

## ğŸ“ Dataset

- **Name**: GTZAN Genre Collection  
- **Source**: GTZAN Dataset on Kaggle (MARSYAS collection)  
- **Description**:
  - 1,000 audio recordings  
  - Duration: 30 seconds per file  
  - Sampling rate: 22050 Hz  
  - Mono channel, 16-bit  
  - 10 genres:
    ```
    blues, classical, country, disco, hiphop,
    jazz, metal, pop, reggae, rock
    ```

âš ï¸ One corrupted Jazz audio file is automatically discarded during preprocessing.

---

## âš™ï¸ Requirements

The experiments were conducted on **Google Colab**.

### Software
- Python **3.11.13**
- TensorFlow **2.18.0**

### Required Libraries
```bash
pip install librosa tensorflow numpy pandas scikit-learn matplotlib tqdm
```
Libraries used:

librosa

tensorflow

numpy

pandas

scikit-learn

matplotlib

tqdm

ğŸ§  Methodology Overview
ğŸ”¹ Audio Segmentation & Feature Extraction
Each 30-second audio file is segmented into 3-second segments
Segment overlap: 50%
Feature extraction: 40 MFCC coefficients
FFT window size: 2048
Hop length: 512
Resulting MFCC shape per segment: (130, 40)
Final CNN input shape: (130, 40, 1)

ğŸ”¹ Dataset Splitting (Song-Level)
Segments from a single song are restricted to one split only.
Training set: 64%, 5% further removed through Local Outlier Factor algorithm
Validation set: 16%
Test set: 20%

After segmentation and cleaning:
Training samples: 12137
Validation samples: 3037
Testing samples: 3798
Total samples before outlier removal: 18972
Total samples before outlier removal: 18365

ğŸ”¹ Outlier Detection
Algorithm: Local Outlier Factor (LOF)
Applied only on training data
Number of neighbors: 20
Contamination factor: 0.05
Outliers removed: 607

ğŸ§± Model Architecture
A CNNâ€“LSTM Evidential Neural Network is employed.
Layer	Output Shape	Parameters
Input	(None, 130, 40, 1)	0
Conv2D (32, 3Ã—3, ReLU)	(None, 130, 40, 32)	320
MaxPooling2D (2Ã—2)	(None, 65, 20, 32)	0
Reshape	(None, 65, 640)	0
LSTM (64 units)	(None, 64)	180480
Dropout	(None, 64)	0
Dense (Softplus, 10)	(None, 10)	650

Total parameters: 181450
Trainable parameters: 181450
Non-trainable parameters: 0

ğŸ§® Evidential Deep Learning Framework
Output activation: Softplus
Evidence computation: e_k = softplus(z_k)
Dirichlet parameters: Î±_k = e_k + 1
Dirichlet concentration: S = Î£ Î±_k
Predictive probability: pÌ‚_k = Î±_k / S

ğŸ”» Loss Function
The total loss is defined as:
L = LNLL + Î» Â· KL
Î» = 1
LNLL: Negative Log-Likelihood
KL: Kullbackâ€“Leibler divergence between predicted Dirichlet distribution and uniform prior

ğŸ‹ï¸ Training Configuration
Optimizer: Adam
Learning rate: 1eâˆ’3
Batch size: 32
Epochs: 40
Metric: Categorical accuracy

ğŸ” Uncertainty Quantification
Uncertainty is computed as: u = K / S
Where:
K = 10 (number of genres)
S = Dirichlet concentration

Reliability Threshold
Reliable prediction: u < 0.4
Unreliable prediction: u â‰¥ 0.4

ğŸ“Š Evaluation Metrics
Classification accuracy
Macro F1-score
Confusion matrix
Expected Calibration Error (ECE)
Reliability diagram
Selective prediction (Accuracy vs Coverage)

ğŸ“ˆ Results Summary
Metric	Value
Training Accuracy	80.64%
Validation Accuracy	72.99%
Test Accuracy	65.81%
Test Loss	1.2574
ECE (before calibration)	0.1401
ECE (after calibration)	0.0791
Optimal temperature	0.6399

ğŸ¯ Selective Prediction
High-confidence samples achieve near-perfect accuracy
Accuracy improves as coverage decreases
Temperature scaling significantly enhances prediction reliability

ğŸ“ Statistical Validation
Statistical test: Wilcoxon signed-rank test
Bootstrap iterations: 1000
Mean ECE reduction: 0.060845
95% confidence interval: [0.034680, 0.087250]
Test statistic: 0
p-value: 3.325859eâˆ’165

âš ï¸ Limitations
Only MFCC features are used
GTZAN dataset contains inherent genre ambiguity
Evaluation is performed in an offline setting

ğŸ“Œ Citation
If you use this work, please cite:
V. Sidharrth, J. Sarada, B. Alatas.
Uncertainty-Aware Music Genre Classification using Evidential Deep Learning.
PeerJ Computer Science (Under Review, 2025).

ğŸ“ License & Contact
This work is intended strictly for academic and educational purposes.

V. Sidharrth
Email: bl.en.u4aid23054@bl.students.amrita.edu

J. Sarada
Email: j_sarada@blr.amrita.edu

B. Alatas
Email: balatas@firat.edu.tr
